import streamlit as st
import time
from datetime import datetime
import threading
import numpy as np
import sounddevice as sd
import whisper
import queue

# =======================
# ‚öôÔ∏è CONFIGURA√á√ïES GERAIS
# =======================

FS = 16000
BUFFER_SIZE = 1024

# Escolha o √≠ndice correto do seu microfone
MIC_DEVICE_INDEX = None  # None usa o dispositivo padr√£o

# =======================
# üîä CARREGAR MODELO WHISPER
# =======================

@st.cache_resource
def carregar_modelo():
    model = whisper.load_model("small")
    if str(model.device) == 'cpu':
        model.fp16 = False
    return model

model = carregar_modelo()

# ================================
# üé§ FUN√á√ïES DE GRAVA√á√ÉO
# ================================

class GravadorAudio:
    def __init__(self):
        self.fs = FS
        self.buffer_size = BUFFER_SIZE
        self.device = MIC_DEVICE_INDEX
        self.stream = None
        self.frames = []
        self.gravando = False
        self.queue = queue.Queue()
    
    def callback(self, indata, frames, time_info, status):
        if status:
            print(f"Erro de √°udio: {status}")
        if self.gravando:
            self.queue.put(indata.copy())
    
    def iniciar(self):
        if self.gravando:
            return
            
        self.gravando = True
        self.frames = []
        self.queue = queue.Queue()
        
        self.stream = sd.InputStream(
            samplerate=self.fs,
            channels=1,
            dtype=np.int16,
            blocksize=self.buffer_size,
            callback=self.callback,
            device=self.device
        )
        self.stream.start()
        return time.time()
    
    def parar(self):
        if not self.gravando:
            return np.array([], dtype=np.int16), 0
            
        self.gravando = False
        
        # Aguarda processamento dos √∫ltimos buffers
        time.sleep(0.5)
        
        # Coleta todos os frames da fila
        while not self.queue.empty():
            self.frames.append(self.queue.get())
        
        if self.stream:
            self.stream.stop()
            self.stream.close()
            self.stream = None
        
        if self.frames:
            audio_array = np.concatenate(self.frames, axis=0)
            duracao = len(audio_array) / self.fs
            return audio_array.flatten(), duracao
        else:
            return np.array([], dtype=np.int16), 0

# ================================
# üéôÔ∏è FUN√á√ÉO DE TRANSCRI√á√ÉO
# ================================

def transcrever_audio(audio_array):
    if audio_array.size == 0:
        return "", 0, 0

    audio_float = audio_array.astype(np.float32) / 32768.0
    inicio = time.time()
    resultado = model.transcribe(audio_float, fp16=False)
    tempo_transcricao = time.time() - inicio
    texto = resultado["text"].strip()
    tempo_audio = len(audio_array) / FS

    print("üìù Transcri√ß√£o:", texto)
    print("‚è± Tempo √°udio:", tempo_audio, "Tempo transcri√ß√£o:", tempo_transcricao)
    return texto, tempo_audio, tempo_transcricao