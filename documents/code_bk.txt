from os.path import join

import nltk
import pandas as pd
import numpy as np
import gensim
import gensim.corpora as corpora
from gensim.models import CoherenceModel
from nltk.corpus import stopwords
from pprint import pprint
import pyLDAvis
import pyLDAvis.gensim_models
import matplotlib.pyplot as plt
import spacy
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from sklearn.pipeline import Pipeline

documents = [
    "A import√¢ncia da autoavalia√ß√£o digital nas empresas modernas.",
    "Em um cen√°rio empresarial cada vez mais competitivo e din√¢mico, compreender o n√≠vel de maturidade digital tornou-se essencial para orientar decis√µes estrat√©gicas.",
    "Muitas empresas, por√©m, ainda enfrentam dificuldades em mensurar sua prontid√£o digital de forma eficaz.",
    "Nesse contexto, solu√ß√µes automatizadas como chatbots inteligentes podem representar uma alternativa vi√°vel para realizar diagn√≥sticos precisos e acess√≠veis.",
    "Ao simular uma conversa natural com o usu√°rio, o chatbot pode coletar informa√ß√µes relevantes sobre pr√°ticas, tecnologias e processos adotados pela organiza√ß√£o.",
    "Com base em modelos estruturados de maturidade digital, a ferramenta √© capaz de oferecer um retorno imediato sobre o est√°gio atual da empresa, al√©m de apontar poss√≠veis √°reas de melhoria.",
    "Essa abordagem reduz custos, aumenta a agilidade do processo de avalia√ß√£o e democratiza o acesso a diagn√≥sticos digitais, especialmente para empresas que n√£o contam com consultorias especializadas.",
    "Ao incorporar intelig√™ncia artificial e t√©cnicas de PLN, o chatbot se torna um aliado estrat√©gico na jornada rumo √† transforma√ß√£o digital."
]


# Exemplo de estrutura real de dados (adaptar para seu contexto):
real_data = {
    "texts": [
        "Qual √© o n√≠vel de ado√ß√£o de cloud computing na empresa?",
        "Voc√™s usam ferramentas de an√°lise de dados?",
        "Como √© a cultura de inova√ß√£o aqui?",
        "Quais tecnologias s√£o utilizadas no processo produtivo?",
        "A empresa tem estrat√©gia clara para transforma√ß√£o digital?"
    ],
    "intents": ["tecnologia", "tecnologia", "cultura", "processos", "estrat√©gia"],
    "maturidade": [3, 2, 1, 2, 4]  # Exemplo de scores (0-5)
}




# Fun√ß√£o de avalia√ß√£o modificada para incluir m√©tricas
def train_and_evaluate(model, model_name, X_train, X_test, y_train, y_test):
    pipeline = Pipeline([
        ('tfidf', TfidfVectorizer(max_features=5000)),
        ('clf', model)
    ])
    
    pipeline.fit(X_train, y_train)
    predictions = pipeline.predict(X_test)
    
    # print(f"\nüîç Resultados para {model_name}:")
    # print(f"Acur√°cia: {accuracy_score(y_test, predictions):.2f}")
    # print("\nRelat√≥rio de Classifica√ß√£o:")
    # print(classification_report(y_test, predictions))
    # print("Matriz de Confus√£o:")
    # print(confusion_matrix(y_test, predictions))
    # print("="*60 + "\n")



def process():

    base_path = "C:\Projetos\chatbot_with_pln\src\data"
    df = pd.read_csv(join(base_path, "digital_maturity_dataset.csv"))
    # df = pd.DataFrame(real_data)

    # Configura√ß√µes iniciais
    nltk.download('stopwords')
    nlp = spacy.load('pt_core_news_lg')

    # Criar um Entity Ruler personalizado
    ruler = nlp.add_pipe("entity_ruler", last=True)

    # Padr√µes de entidades baseados na OntoMaturity (exemplo)
    patterns = [
        {"label": "TECNOLOGIA", "pattern": "nuvem"},
        {"label": "TECNOLOGIA", "pattern": "cloud computing"},
        {"label": "TECNOLOGIA", "pattern": "intelig√™ncia artificial"},
        {"label": "PROCESSO", "pattern": "metodologias √°geis"},
        {"label": "PROCESSO", "pattern": "automa√ß√£o"},
        {"label": "ESTRAT√âGIA", "pattern": "roadmap"},
        {"label": "CULTURA", "pattern": "resist√™ncia √† mudan√ßa"},
        {"label": "DADOS", "pattern": "governan√ßa de dados"}
    ]

    ruler.add_patterns(patterns)

    # Aplicar a fun√ß√£o a cada texto do DataFrame
    df["entities"] = df["text"].apply(lambda x: extract_entities(x, nlp))

    # entities = extract_entities(df["text"], nlp)
    print(df["entities"])
    

    df.to_csv(join(base_path, "dataframe_processed.csv"),index=False,sep=";")
    # # 1. Pr√©-processamento
    # print("üõ†Ô∏è Pr√©-processando documentos...")
    # processed_tokens = preprocess_with_spacy(documents, nlp)
    
    # # Ap√≥s criar o dataset real:
    # X_train, X_test, y_train, y_test = train_test_split(
    #     df["text"], df["intent"], test_size=0.2, random_state=42
    # )

    # # Pipeline otimizado para maturidade digital
    # pipeline = Pipeline([
    #     ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2))),
    #     ('clf', LogisticRegression(class_weight='balanced'))  # Melhor para dados desbalanceados
    # ])

    # pipeline.fit(X_train, y_train)
    
    # # 2. Modelagem de T√≥picos (LDA)
    # print("\nüß† Executando modelagem de t√≥picos...")
    # id2word = corpora.Dictionary(processed_tokens)
    # corpus = [id2word.doc2bow(text) for text in processed_tokens]
    
    # lda_model = gensim.models.LdaModel(
    #     corpus=corpus,
    #     id2word=id2word,
    #     num_topics=3,
    #     random_state=42,
    #     passes=15
    # )
    
    # # C√°lculo de coer√™ncia
    # coherence_model = CoherenceModel(
    #     model=lda_model,
    #     texts=processed_tokens,
    #     dictionary=id2word,
    #     coherence='c_v'
    # )
    
    # # Visualiza√ß√£o
    # print("\nüé® Gerando visualiza√ß√£o...")
    # vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)
    # pyLDAvis.display(vis)
    
    # # 3. Classifica√ß√£o (Exemplo com dados simulados)
    # print("\nü§ñ Treinando modelos de classifica√ß√£o...")
    
    # # Criando labels fict√≠cias para demonstra√ß√£o
    # y = np.array([0, 0, 0, 0, 1, 1, 1, 1])  # 0: conceitos gerais, 1: chatbots
    # X = [' '.join(tokens) for tokens in processed_tokens]  # Convertendo tokens para texto
    
    # # Divis√£o dos dados
    # X_train, X_test, y_train, y_test = train_test_split(
    #     X, y, test_size=0.25, random_state=42, stratify=y
    # )
    
    # # Modelos para testar
    # models = [
    #     (MultinomialNB(), "Naive Bayes")
    #     # (LogisticRegression(max_iter=1000), "Regress√£o Log√≠stica"),
    #     # (RandomForestClassifier(n_estimators=100), "Random Forest")
    # ]
    
    
    # # Treino e avalia√ß√£o
    # for model, name in models:
    #     train_and_evaluate(model, name, X_train, X_test, y_train, y_test)

    
    print("| ### ‚úÖ Finishing the process... ### |")