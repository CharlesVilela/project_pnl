# **README ‚Äì Chatbot: TransformMind**

## **1. TransformMind**

Um chatbot inteligente para responder d√∫vidas sobre transforma√ß√£o digital, maturidade digital, tecnologias emergentes e estrat√©gias organizacionais.

---

## **2. Descri√ß√£o Geral**
 
### O que?

A transforma√ß√£o digital tornou-se um fator determinante para a competitividade e inova√ß√£o nas organiza√ß√µes. No entanto, avaliar o n√≠vel de maturidade digital de uma empresa ainda √© um desafio complexo, que requer a an√°lise de m√∫ltiplos fatores, como cultura organizacional, ado√ß√£o de tecnologia, processos e estrat√©gias.

Este projeto prop√µe o desenvolvimento de um chatbot para interagir com usu√°rios e avaliar o n√≠vel de maturidade digital de suas organiza√ß√µes com base em par√¢metros estruturados previamente definidos por meio de pesquisa.


### Por que?

Atualmente, a avalia√ß√£o da maturidade digital √© feita por diagn√≥sticos manuais, consultorias especializadas ou question√°rios extensos, sendo processos custosos, demorados e subjetivos. Muitas organiza√ß√µes n√£o possuem recursos ou conhecimento suficiente para realizar uma autoavalia√ß√£o eficaz. Um chatbot automatiza essa tarefa, oferecendo:

 - Experi√™ncia interativa e acess√≠vel
 - Autoavalia√ß√£o r√°pida
 - Resultados baseados em dados e ontologias validadas

### Como?

O chatbot utiliza t√©cnicas de Processamento de Linguagem Natural (PLN), incluindo:

NLU (Natural Language Understanding) para compreens√£o do usu√°rio

NLG (Natural Language Generation) para gerar respostas naturais

Seu modelo de aprendizado √© treinado aplicando Machine Learning e redes neurais para melhorar a precis√£o da classifica√ß√£o.

### Objetivo 

Usar as tecnicas e ferramentas de Processamento de Linguagem Natural (PLN) para desenvolver um chatbot com o intuito de avaliar a maturidade digital dentro das organiza√ß√µes, por meio de intera√ß√µes com usu√°rios. Avaliando o nivel de maturidade digital por meio de parametros estruturados, pois, o contexto de Transforma√ß√£o digital se tornou determinante para a inova√ß√£o e competitividade das organiza√ß√µes requerindo um analise de fatores, como *cultura organizacional*, *ado√ß√£o de tecnologia*, *processos* e *estrat√©gias*. Com isso, podemos proporcionar √†s organiza√ß√µes  uma ferramenta para avalia√ß√£o da maturidade digital, auxiliando na identifica√ß√£o de lacunas e formula√ß√£o de estrategias de transforma√ß√£o digital.

---

## üîß **3. Funcionalidades**

Principais funcionalidades implementadas:

* Responder perguntas sobre transforma√ß√£o digital
* Classifica√ß√£o de intents (ex: customer experience, processos, cultura)
* Extra√ß√£o de entidades relevantes
* Gera√ß√£o de respostas contextualizadas
* Rephrase de perguntas para treinamento cont√≠nuo

---

## üèóÔ∏è **4. Estrutura do Projeto**

Organiza√ß√£o dos arquivos e pastas:

```
/chatbot_transformacao_digital
‚îÇ
‚îú‚îÄ‚îÄ data/                               # Bases de conhecimento e datasets
‚îú‚îÄ‚îÄ documents/                      # Documentos brutos (PDFs, artigos, relat√≥rios)
‚îú‚îÄ‚îÄ input/                          # Arquivos de entrada para processamento
‚îú‚îÄ‚îÄ output/                         # Resultados processados e datasets finais
‚îÇ
‚îú‚îÄ‚îÄ model_train/                        # Diret√≥rio de modelos treinados organizados
‚îÇ   ‚îú‚îÄ‚îÄ model_train_category/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ versions/                   # Vers√µes de modelos de classifica√ß√£o de categoria
‚îÇ   ‚îú‚îÄ‚îÄ model_train_intent/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ versions/                   # Vers√µes de modelos de classifica√ß√£o de intents
‚îÇ   ‚îî‚îÄ‚îÄ model_train_maturity_score/
‚îÇ       ‚îî‚îÄ‚îÄ versions/                   # Vers√µes de modelos de maturidade digital
‚îÇ
‚îú‚îÄ‚îÄ image/                              # Imagens geradas, plots de treinamento e resultados
‚îÇ   ‚îú‚îÄ‚îÄ model_train_category/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ versions/                   # Gr√°ficos do treinamento do modelo de categoria
‚îÇ   ‚îú‚îÄ‚îÄ model_train_intent/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ versions/                   # Gr√°ficos do treinamento do modelo de intents
‚îÇ   ‚îî‚îÄ‚îÄ model_train_maturity_score/
‚îÇ       ‚îî‚îÄ‚îÄ versions/                   # Gr√°ficos do treinamento do modelo de maturidade digital
‚îÇ
‚îú‚îÄ‚îÄ log/                                # Logs de execu√ß√£o e treinamentos
‚îÇ
‚îú‚îÄ‚îÄ src/                                # C√≥digo-fonte principal
‚îÇ   ‚îú‚îÄ‚îÄ dao/                            # Data Access Objects (interfaces com banco de dados)
‚îÇ   ‚îú‚îÄ‚îÄ helpers/                        # Fun√ß√µes utilit√°rias gerais para o projeto
‚îÇ   ‚îú‚îÄ‚îÄ model/                          # Scripts de treinamento e avalia√ß√£o de modelos
‚îÇ   ‚îú‚îÄ‚îÄ resource/                       # Arquivos de configura√ß√£o, dicion√°rios, mappings
‚îÇ   ‚îú‚îÄ‚îÄ utils/                          # Fun√ß√µes utilit√°rias espec√≠ficas (ex: logs, formata√ß√£o)
‚îÇ   ‚îú‚îÄ‚îÄ main.py                        # Script principal para execu√ß√£o geral do projeto (como extra√ß√£o de dados, treinamento dos modelos e teste das intera√ß√µes com os modelos)
‚îÇ   ‚îî‚îÄ‚îÄ main_chatbot.py                # Script principal com a interface gr√°fica do chatbot (integrado o o streamlit)
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt                   # Depend√™ncias do projeto
‚îú‚îÄ‚îÄ README.md                          # Documenta√ß√£o geral
‚îî‚îÄ‚îÄ LICENSE                            # Licen√ßa de uso

```

---

## üß† **5. Tecnologias e Ferramentas**

As principais tecnologias utilizadas:

* **Linguagem:** Python 3.9.13
* **Bibliotecas:**
---

1. ### **Pacotes de NLP e Transformers**

   * `accelerate==1.4.0`
   * `transformers==4.41.0`
   * `sentence-transformers==3.4.1`
   * `sentencepiece==0.2.0`
   * `keybert==0.9.0`
   * `deep-translator==1.11.4`
   * `langid==1.1.6`
   * `langcodes==3.5.0`
   * `huggingface-hub==0.29.1`
   * `datasets==3.3.2`

2. ### **Spacy e modelos**

   * `spacy==3.8.7`
   * `en-core-web-sm`
     [Baixar modelo](https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl)
   * `pt-core-news-sm`
     [Baixar modelo](https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.8.0/pt_core_news_sm-3.8.0-py3-none-any.whl)
   * `spacy-legacy==3.0.12`
   * `spacy-loggers==1.0.5`

3. ### **Pr√©-processamento e NLP Cl√°ssico**

   * `nltk==3.9.1`
   * `regex==2024.11.6`

4. ### **Machine Learning**

   * `scikit-learn==1.6.1`
   * `scipy==1.10.1`
   * `joblib==1.4.2`
   * `torch==2.3.0`

5. ### **Visualiza√ß√£o de Dados**

   * `matplotlib==3.9.4`
   * `matplotlib-inline==0.1.7`
   * `seaborn==0.13.2`
   * `plotly==5.22.0`
   * `pyLDAvis==3.4.1`

6. ### **Manipula√ß√£o de Dados**

   * `numpy==1.26.4`
   * `pandas==2.2.3`

7. ### **Streamlit e Utilit√°rios Web**

   * `streamlit==1.36.0`
   * `python-dotenv==1.0.1`

8. ### **Outros Utilit√°rios**

   * `decorator==5.2.1`
   * `python-json-logger==3.2.1`
   * `python-dateutil==2.9.0.post0`
   * `pytz==2025.1`
   * `pyparsing==3.2.3`
   * `PyPDF2==3.0.1`
   * `pymongo==4.13.0`
   * `language_data==1.3.0`

---

* **Modelos:**

    * `Vamsi/T5_Paraphrase_Paws`
    * `google/flan-t5-base`
    * `paraphrase-mpnet-base-v2`
    * `all-MiniLM-L6-v2`
    * `BERT`

* **Outros:** Git e VSCode.

---

## üöÄ **6. Como Executar o Projeto**

Passo a passo para execu√ß√£o local:

1. Clone o reposit√≥rio

   ```bash
   git clone https://github.com/CharlesVilela/project_pnl.git
   cd chatbot_transformacao_digital
   ```
2. Crie um ambiente virtual

   ```bash
   python -m venv venv
   source venv/bin/activate  # Linux/macOS
   venv\Scripts\activate     # Windows
   ```
3. Instale as depend√™ncias

   ```bash
   pip install -r requirements.txt
   ```
4. Execute a aplica√ß√£o

   ```bash
   streamlit run src/app.py
   ```

---

## üß™ **7. Exemplos de Uso**

### Exemplo 1 - Intera√ß√£o por texto
> **Usu√°rio (texto):** O que √© exatamente a transforma√ß√£o digital no cen√°rio de neg√≥cios atual?<br>
> **Chatbot (texto):** - A transforma√ß√£o digital no cen√°rio de neg√≥cios atual √© uma mudan√ßa na maneira como as empresas operam e interagem com seus clientes, funcion√°rios e outras partes interessadas. √â tamb√©m uma mudan√ßa na maneira como as pessoas interagem com produtos e servi√ßos, bem como como as empresas podem fazer melhor uso da tecnologia e da infraestrutura, relata o Wall Street Journal. "A transforma√ß√£o digital √© a evolu√ß√£o da capacidade de uma organiza√ß√£o de ser mais eficiente, mais receptiva e mais receptiva √†s necessidades dos clientes", diz um especialista em transforma√ß√£o digital da Universidade da Calif√≥rnia, Berkeley. "Est√° mudando a maneira como interagimos com nossos clientes, tornando -os mais conscientes do que eles podem fazer e de como eles podem ajud√° -los a alcan√ßar seus objetivos".

### Exemplo 2 - Intera√ß√£o por √°udio
> **Usu√°rio (√°udio):** [√Åudio enviado dizendo: "Como uma empresa pode identificar sua prontid√£o para a transforma√ß√£o digital?"]

**Processo**<br>
1. O chatbot transcreve o √°udio para texto utilizando o m√≥dulo de transcri√ß√£o.

2. Realiza a busca sem√¢ntica e classifica√ß√£o de intent.

3. Gera a resposta textual.

4. (Opcional) Converte a resposta em √°udio usando o m√≥dulo de TTS (text-to-speech) e envia ao usu√°rio.

> **Chatbot (resposta textual):** - Um "n√≠vel de maturidade" indica que o est√°gio atual da organiza√ß√£o na maturidade digital, e uma "recomenda√ß√£o pr√°tica" √© uma boa maneira de avaliar a prontid√£o da empresa para a transforma√ß√£o digital. Por exemplo, se voc√™ √© uma empresa emergente, concentre -se na integra√ß√£o, consist√™ncia e alinhamento interno. Para uma empresa l√≠der, destaque otimiza√ß√£o, escalabilidade e desempenho. Para uma organiza√ß√£o emergente, enfatize a inova√ß√£o, a orquestra√ß√£o do ecossistema e a diferencia√ß√£o competitiva.
> **Chatbot (resposta √°udio):**[√Åudio com a resposta acima gerada com TTS]

---

## ‚òÅ **8. O armazenamento**
Para o armazenamento dos dados foi utilizado o banco de dados **MongoDB Atlas**. Por conta:

  1. **Escalabilidade e Flexibilidade:**
    MongoDB Atlas oferece escalabilidade horizontal autom√°tica, permitindo o armazenamento de grandes volumes de dados n√£o estruturados ou semiestruturados sem restri√ß√µes rigidas de esquema

  2. **Modelo de dados Natural para documentos NLP:**
    Utiliza o formato JSON-like (BSON), que se adapta a documentos de conhecimento, resultados de infer√™ncias, classifica√ß√µes de intents e entities, eliminando a necessidade de m√∫ltiplas tabelas relacionais complexas.

  3. **F√°cil integra√ß√£o com aplica√ß√µes Python:**
    Com bibliotecas como pymongo e conectores nativos, a integra√ß√£o com o pipeline de processamento de linguagem natural √© direta, permitindo armazenar e consultar resultados de forma r√°pida.
  4. **Disponibilidade Multi-Cloud:**
    Permite deploy em diferentes provedores e regi√µes, aumentando a flexibilidade e ader√™ncia a estrat√©gias corporativas multicloud.

O banco de dados se divide em dois tipos de dados: o primeiro utilizado para o treinamento do modelo e consulta do contexto para a gera√ß√£o de resposta do chatbot; e o segundo que armazena um cache de intera√ß√µes dos usu√°rios que √© utilizado para otimizar o tempo de resposta do chatbot.

### üíæ **1. Dataset - Treinamento do modelo**

Como n√£o foi encontrada uma base p√∫blica pronta, foi criada uma **base de dados pr√≥pria** utilizando:

### üîé **Fontes**

1. **Artigos acad√™micos**

   * *Exemplo:* **Digital transformation: What we have learned (thus far) and what is next** ‚Äì Consensus

| **Tipo**         | **T√≠tulo**                                                                 | **Autor** | **Ano de publica√ß√£o** |
| ---------------- | -------------------------------------------------------------------------- | --------- | --------------------- |
| `artigo`         | A Systematic Review of the Literature on Digital Transformation: Insights and Implications for Strategy and Organizational Change |  Andr√© Hanelta, Ren√© Bohnsack et. all         | 2021                     |
| `artigo`         | Understanding digital transformation: A review and a research agenda                                               | Gregory Vial         | 2019                     |
| `artigo`          | Digital transformation: a review, synthesis and opportunities for future research                            | Swen Nadkarni e Reinhard Prugl        | 2020                     |
| `artigo` | Digital transformation: A review and research agenda                                       | Dmitry Plekhanov, Henrik Franke et. all         | 2023                    |
| `artigo`      | Digital transformation: What we have learned (thus far) and what is next | Sabrina Schneider e Olga Kokshagina | 2020                  |
| `artigo`         | Digital transformation: A multidisciplinary reflection and research agenda                                               | Peter C. Verhoef, Thijs Broekhuizen et. all         | 2019                     |
| `artigo`          | Digital Transformation Leadership Characteristics: a Literature Analysis                            |  Patrick McCarthy, David Sammon et. all       | 2021                    |
| `artigo` | Defining digital transformation: Results from expert interviews                                       | Ines Mergel, Noella Edelmann et. all        | 2019                    |
| `artigo`      | Influence of Digital Transformation Capability on Operational Performance | Jiatong Yu, Jiajue Wang et. all | 2022                  |
| `artigo`         | The role of digital transformation practices in the operations improvement in manufacturing firms: A practice-based view                                               | Meng Tian, Yang Chen et. all         | 2023                    |
| `artigo`          | The Effects of Digital Transformation on Firm Performance: Evidence from China's Manufacturing Sector                 | Lei Guo e Luying Xu        | 2021                    |
| `artigo` | Does digital transformation improve the operational efficiency of Chinese power enterprises         | Boqiang Lin e Yongjing Xie        | 2023                     |
| `artigo`      | Digital Transformation in Business Operations Management | Nur Rohmah e Komarudin | 2023                  |
| `artigo`         | Operational research and business intelligence as drivers for digital transformation          | Pavlos Delias e Fotis C. Kitsios         | 2023                     |
| `artigo`          | Digital Transformation in Process Industries                   | Joseph Ting         | 2021                     |
| `artigo` | Research on the Impact of Digital Transformation on Enterprise Operational Efficiency           | Boru Lei         | 2025                    |
| `artigo`      | Broadband infrastructure and enterprise digital transformation: Evidence from China | Meng Li, Zhengqi Wang et. all | 2024                  |
| `artigo`         | Transforming the Customer Experience Through New Technologies                                              | Wayne D. Hoyer, Mirja Kroschke et. all         | 2020                     |
| `artigo`          | Solving the crisis of immediacy: how digital technology can transform the customer experience        | Salvatore Parise, Patricia J. Guinan et. all         | 20216                    |
| `artigo` | Digital Transformation and the Customer Experience: Enhancing Engagement and Loyalty | Antonius Felix e Glisina Dwinoor Rembulan        | 2023                   |
| `artigo`     | The Effects of Digital Transformation on Firm Performance: The Role of Customer Experience and IT Innovation | Rawan Masoud e Sarah Basahel | 2023                  |
| `artigo`         | The digital transformation of business. Towards the datafication of the relationship with customers     | Cristina Fern√°ndez-Rovira, Jes√∫s √Ålvarez Vald√©s et. all        | 2021                    |
| `artigo`          | Digital transformation and customer value creation in Made in Italy SMEs: A dynamic capabilities perspective      | Michela Matarazzo, Lara Penco et. all         | 2021                     |
| `artigo` | Complexity of Creating Customer Experience under the Influence of Digital Transformation  | Iva Gregurec, Lucija Tomasek et. all         | 2022                     |
| `artigo`      | Exploring the Impact of Digital Transformation on Business Operations and Customer Experience | Dr. Sayyad Vakeel Agmad Munaf Ali, Dr. Monika Sharma et. all | 2024                  |
| `artigo`         | Adoption paths of digital transformation in manufacturing SME    | Elisa Battistoni, Simone Gitto et. all         | 2022                   |
| `autor`          | Nome do(s) autor(es) ou organiza√ß√£o respons√°vel                            | -         | -                     |
| `ano_publicacao` | Ano em que o documento foi publicado                                       | -         | -                     |
| **Exemplo**      | *Digital transformation: What we have learned (thus far) and what is next* | Consensus | 2024                  |



---

### üåê **Sites consultados**

* [Google Academico](https://scholar.google.com/?hl=pt-BR)
* [Consensus](https://consensus.app/search/)

---

#### üóÉÔ∏è **Estrutura da base de dados**

| **Campo**        | **Descri√ß√£o**                                                    |
| ---------------- | ---------------------------------------------------------------- |
| `text`           | Pergunta, afirma√ß√£o ou trecho relevante extra√≠do                 |
| `intent`         | Inten√ß√£o comunicativa do texto                                   |
| `maturity_score` | Grau de maturidade digital (0 a 1)                               |
| `entities`       | Lista de entidades nomeadas (ex: organiza√ß√µes, pessoas, locais)  |
| `category`       | Classifica√ß√£o geral (ex: arquitetura organizacional, estrat√©gia) |
| `metadata`       | Informa√ß√µes adicionais (fonte, data, autor, etc)                 |


### üîÑ **2. Dataset - Cache das intera√ß√µes**

O objetivo da utiliza√ß√£o do cache de intera√ß√µes √© otimizar o tempo de resposta levado para o chatbot consegui retornar uma resposta para o usu√°rio.

#### **Estrutura do Cache de Intera√ß√µes**

| **Campo**        | **Descri√ß√£o**                                                    |
| ---------------- | ---------------------------------------------------------------- |
| `user_input`           | Pergunta do usu√°rio                |
| `response`         | Resposta gerada pelo chabot                                    |
| `userid` | Identificador da sess√£o, ou seja, para cada sess√£o iniciada √© gerado um uuid daquela sess√£o                                |
| `timeresponse`       | Tempo que o chatbot leva para gerar uma resposta  |
| `datetime`       | Data e hora da intera√ß√£o |
| `isQuestionAudio`       | Indica se a pergunta do usu√°rio foi em audio                |
| `isResponseAudio`       | Indica se a resposta do chatbot foi em audio                |


---

## üìä **9. Metodologia**

- A base de dados foi criada manualmente por meio de artigos baseados em Maturidade digital. Com isso, o sistema conta com uma base de conhecimento fundamental em maturidade digital, que foi aprimorado com tecnicas de aprendizado de maquina (ML) e redes neurais para melhorar a classifica√ß√£o do modelo.
  
- Utilizado para o desenvolvimento desse chatbot:
  - Natural Lanaguage Undestanding - (NLU)
  - Natural Language Generation - (NLG) 

 Abordagem explicada:

* Pr√©-processamento (tokeniza√ß√£o, stopwords)
  * Utiliza-se o spaCy com o modelo `en_core_web_sm` para:
    * Criar um Entity Ruler personalizado para identifica√ß√£o de entidades especificas nos textos
    * Realizar a tokeniza√ß√£o e lematiza√ß√£o de cada texto, gerantindo a padroniza√ß√£o linguistica antes do trienamento.
    * Ap√≥s o pr√©-processamento, os dados passam pela fun√ß√£o `map_score_to_label(score)`, que mapeia os scores dos textos em tr√™s classes:
     * 'low', 'average' e 'high'
       
* Vetoriza√ß√£o ou embeddings utilizados
  * √â aplicado TF-IDF para gerar a matriz de vetores:

    ```
      tfidf_vectorizer = TfidfVectorizer(stop_words='english')
      tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)
     ```

   * Al√©m do TF-IDF, s√£o gerados **embeddings sem√¢nticos** com o **SentenceTransformer**, utilizando dois modelos principais:
      * `"all-MiniLM-L6-v2"` para tarefas gerais de embeddings
      * `"paraphrase-mpnet-base-v2"` para tarefas de similaridade sem√¢ntica mais robusta
        
* Algoritmos de classifica√ß√£o ou gera√ß√£o de texto
   * Classifica√ß√£o
      * Para tarefas de maturity_label e intent, s√£o utilizados tr√™s algoritmos cl√°ssicos de Machine Learning:
         * Naive Bayes
         * Logistic Regression
         * Random Forest
   * Modelos carregados
      * Modelos treinados como **Logistic Regression** s√£o carregados via `joblib.load` nos caminhos salvos para intent e maturity:

        ```
          intent_model = joblib.load(intent_model_path)
          maturity_model = joblib.load(maturity_model_path)
        ```
    * Gera√ß√£o de texto
       * **Paraphrase Pipeline** com o modelo **"Vamsi/T5_Paraphrase_Paws"** para reescrita de textos.
       * **Flan-T5** `google/flan-t5-base` para tarefas de gera√ß√£o de sequ√™ncia de texto (seq2seq) com suporte a infer√™ncia em **float16** para melhor desempenho.
           
* M√©tricas de avalia√ß√£o e resultados


## **10. Resultados**

Os resultados se dividem em tr√™s pontos: o funcionamento do chatbot, analise dos resultados dos modelos treinados e a analise das respostas do chatbot. <br><br>

![Figura 01 - Fluxo do chatbot](image/img_readme/fluxo_chatbot_mains.png)

O projeto do chatbot se divide em tr√™s partes.

1. O primeiro main √© mais voltado para a extra√ß√£o de textos de artigos/livros e do treinamento dos modelos de redes neurais
   - **Parte 1: Extra√ß√£o de textos**
     - Extrai os textos do PDF
       - Limpa textos
     - Extrai as keywords
       - Usa o modelo KeyBERT
     - Identifica o idioma (se o texto √© em portugu√™s ou ingl√™s) para usar o mapeamento correto das categorias com suas palavras-chave
     - Extrai as frases mais relevantes
       - Usa SentenceTransformer
     - Gera um dataset com esses textos
       - Traduz o texto (se for em portugu√™s, traduz para ingl√™s)
       - Atribui o score
       - Atribui o intent
       - Atribui as entities
       - Atribui a categoria
       - Salva na base de dados

   - **Parte 2: Treinamento dos modelos**
     - L√™ a base de dados com os textos extra√≠dos
     - Pr√©-processa os dados
       - Tokeniza√ß√£o e lematiza√ß√£o com Spacy
     - Treina os modelos
       - Naive Bayes
       - Logistic Regression
       - Random Forest

2. O segundo main √© mais voltado para a parte da intera√ß√£o do usu√°rio com o chatbot, ou seja, nesse main temos o front end do projeto que permite conversar com o chatbot.

   - **Fluxo desse main:**
     - O usu√°rio faz uma pergunta que pode ser em:
       - √Åudio
       - Texto
     - Se for em √°udio:
       - Transcreve o √°udio para texto
     - A pergunta do usu√°rio √© buscada primeiramente na base de dados cache
       - Se na base de dados cache j√° existir uma pergunta 95% similar:
         - Retorna a mesma resposta que est√° no banco de cache
       - Se a pergunta n√£o estiver na base de dados cache:
         - Passa a pergunta para o modelo
           - Antes de ir diretamente para o modelo:
             - A pergunta do usu√°rio √© traduzida para o ingl√™s
           - Depois da tradu√ß√£o:
             - O modelo faz uma busca sem√¢ntica junto com TF-IDF para buscar o contexto na base de dados
             - O modelo gera uma resposta
           - Com a resposta do modelo gerada:
             - Traduz a resposta para o portugu√™s
           - Caso a op√ß√£o de resposta em √°udio esteja ativada:
             - Converte o texto em √°udio
         - Retorna a resposta para o usu√°rio


### Resultado da analise das respostas do chatbot

A analise dos dados gerados pelo chatbot seguem o fluxo da Figura 02

![Figura 02 - Fluxo dos testes](image/img_readme/fluxo_test_desempenho.png)

1. Pergunta de Teste
   * Input: Quest√µes do dataset de valida√ß√£o (ex: "Como a transforma√ß√£o digital impacta cadeias de suprimentos?")
   * C√≥digo relacionado: `conversation_chatbot()` que processa perguntas atrav√©s do modelo
2. Resposta Gerada vs Resposta Esperada
    * Compara√ß√£o entre:
      * Sa√≠da do modelo (resposta gerada)
      * Resposta de refer√™ncia (gold standar)
     * C√≥digo `calculate_similarity` que usa embeddings para comparar semelhan√ßa
3. Avalia√ß√£o Autom√°tica
    * M√©tricas calculadas
       * Similaridade (Cosine): `cosine_similarity(response_embedding, reference_embedding)`
       * BLEU: `sentence_bleu([reference_tokens], generated_tokens)`
       * ROUGE-L: `rouge_l_score(reference, generated)`
       * METEOR: `meteor_score([reference], generated)`
     * C√≥digo: `test_analise.py` contendo todas as fun√ß√µes de c√°lculo
4. Relat√≥rio Consolidado
    * Agrega resultados de todas as perguntas
    * Gera estrutura JSON com:
       * M√©tricas m√©dias
       * Resultados detalhados por pergunta
       * Identifica√ß√£o de pontos fracos
 5. An√°lise de Pontos Fracos
   * Detecta padr√µes problem√°ticos

     ```
        def identify_weak_points(self):
        """Identifica √°reas problem√°ticas com base nas avalia√ß√µes"""
        weak_points = {
            "low_semantic_similarity": [],
            "human_low_scores": []
        }
        
        # Identificar respostas com baixa similaridade sem√¢ntica
        for item in self.results:
            if item['auto_metrics']['cosine_similarity'] < 0.6:
                weak_points["low_semantic_similarity"].append({
                    "question": item['question'],
                    "score": item['auto_metrics']['cosine_similarity']
                })
        
        # Identificar respostas com baixa avalia√ß√£o humana
        for item in self.results:
            if item['human_evaluation']:
                low_scores = [
                    metric for metric, score in item['human_evaluation']['scores'].items() 
                    if score < 3
                ]
                if low_scores:
                    weak_points["human_low_scores"].append({
                        "question": item['question'],
                        "criteria": low_scores,
                        "comments": item['human_evaluation']['comments']
                    })
        
        return weak_points
     ```
### Analise do treinamento

Os modelos foram treinados para 2 tarefas distintas:
   * `maturity_label` (Classifica√ß√£o de maturidade)
   * `intent` (Classifica√ß√£o de inten√ß√£o

Cada tarefa foi testada com 3 algoritmos: Naive Bayes, Regress√£o Log√≠stica e Random Forest

#### Tabelas
##### **1. Maturity Label**

| **Modelo**           | **Accuracy** | **Macro Avg (F1-score)** | **Weighted Avg (F1-score)** |
|-----------------------|:------------:|:------------------------:|:---------------------------:|
| Naive Bayes           | 0.911        | 0.493                    | 0.894                       |
| Logistic Regression   | 0.937        | 0.661                    | 0.933                       |
| Random Forest         | 0.950        | 0.738                    | 0.949                       |

---

##### **2. Intent**

| **Modelo**           | **Accuracy** | **Macro Avg (F1-score)** | **Weighted Avg (F1-score)** |
|-----------------------|:------------:|:------------------------:|:---------------------------:|
| Naive Bayes           | 0.843        | 0.096                    | 0.801                       |
| Logistic Regression   | 0.925        | 0.248                    | 0.917                       |
| Random Forest         | 0.952        | 0.422                    | 0.947                       |

### Principais Padr√µes Observados

1. **Maturity Label**
    * Melhor modelo: Random Forest
        * Accuracy: 0.950
        * Macro Avg F1: 0.738
        * Weighted Avg F1: 0.949
     * Observa√ß√µes:
         * O Random Forest apresentou desempenho superior em todas as m√©tricas.
         * Logistic Regression tamb√©m teve performance alta, mas levemente inferior em macro avg, indicando menor equil√≠brio entre classes.
         * Naive Bayes teve o pior desempenho, especialmente na macro avg (0.493), evidenciando dificuldade em classes minorit√°rias.

2. Intent
    * Melhor modelo: Random Forest
      * Accuracy: 0.952
      * Macro Avg F1: 0.422
      * Weighted Avg F1: 0.947
    * Observa√ß√µes
       * Apesar da alta accuracy (~95%), o macro avg F1 √© baixo (0.422) em todos os modelos, sugerindo que:

         * O modelo acerta predominantemente classes majorit√°rias.
         * Classes minorit√°rias t√™m performance insatisfat√≥ria.

       * Logistic Regression apresentou macro avg F1 melhor (0.248) que Naive Bayes (0.096), mas ambos muito baixos.
          
**Insights Gerais**
 - Random Forest foi consistentemetne o melhor modelo em todas as tarefas
 - Logistic Regression teve desempenho competitivo, especialmente para maturity_label
 - Naive Bayes apresentou desempenho fraco, sugerindo inadequa√ß√£o aos seus dados de alta dimensionaldiade e distribui√ß√£o desequilibrada.



<br>
### Desempenho do chatbot

A tabela abaixo √© uma pequena amostra dos dados gerados pelos modelos de avalia√ß√£o. Para ver o arquivo json completo clique aqui: [Ver arquivo JSON completo](full_evaluation_report.json)

##### Desempenho do Modelo (Resumo)

| Categoria          | M√©trica             | Valor M√©dio | Observa√ß√£o                           |
|--------------------|---------------------|-------------|--------------------------------------|
| **Amostra**        | Total de Respostas  | 67          |                                      |
| **Similaridade**   | Cosine Similarity   | 0.6816      | 0 (sem rela√ß√£o) ‚Üí 1 (id√™ntico)       |
| **Qualidade**      | ROUGE-L             | 0.0903      | Coer√™ncia de sequ√™ncias              |
|                    | METEOR Score        | 0.0993      | Precis√£o por alinhamento             |
|                    | BLEU Score          | 0.0027      | Similaridade n-gram                  |
| **Humano**         | Relev√¢ncia          | 2.6/5       | Rela√ß√£o com o tema                   |
|                    | Corre√ß√£o            | 2.0/5       | Precis√£o factual                     |
|                    | Completude          | 1.6/5       | Abrang√™ncia da resposta              |
|                    | Clareza             | 2.0/5       | Facilidade de compreens√£o            |

**Principais Insights**

1. For√ßas
   * Boa compreens√£o conceitual (similaridade sem√¢ntica aceitavel)
   * Desempenho superior em t√≥picos estrat√©gicos (ex: defini√ß√µes de transforma√ß√£o digital)
2. Desafios Cr√≠ticos
    * Baixa completude (63% abaixo do esperado)
    * Clareza insuficiente (40% das respostas confusas)
    * Problemas graves em temas t√©cnicos especificos
3. Futuras melhorias
    * Implementar verifica√ß√µes contra alucina√ß√µes
    * Desenvolver submodelos especializados para dom√≠nios t√©cnicos



**Principais Desafios:**  
‚ñ∏ Completude 68% abaixo do ideal  
‚ñ∏ Clareza insuficiente em 40% das respostas  
‚ñ∏ Dificuldade em t√≥picos t√©cnicos espec√≠ficos

---

## üë• **10. Contribuidores**

Os membros do projeto:

* **Charles Vilela** ‚Äì [GitHub](https://github.com/charlesvilela) | [LinkedIn](https://linkedin.com/in/charlesvilela)
* **Gabriel Lima** ‚Äì [GitHub](https://github.com/Gabs19) | [LinkedIn](https://www.linkedin.com/in/gabriel-lima-861181168/)

---

## üí° **11. Futuras Implementa√ß√µes**

Melhorias ou pr√≥ximos passos:

* Treinar modelos maiores para gera√ß√£o de resposta
* Deploy em nuvem (AWS, GCP)
* Melhorar integra√ß√£o com plataformas de atendimento ao cliente
* Dashboard de analytics de intera√ß√£o

---

